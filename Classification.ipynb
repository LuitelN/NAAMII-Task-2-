{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e593cc8b",
   "metadata": {},
   "source": [
    "Libraries Import \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02f5d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, confusion_matrix, f1_score\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c66c6ae",
   "metadata": {},
   "source": [
    "Loading the CSV files \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2151a444",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_set.csv\")\n",
    "test_df = pd.read_csv(\"test_set.csv\")\n",
    "blind_df = pd.read_csv(\"blinded_test_set.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949be693",
   "metadata": {},
   "source": [
    "Working on Training Set Data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e45557ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID     Feature_1  Feature_2     Feature_3  Feature_4  Feature_5  \\\n",
      "0  ID_1  18281.541667    18432.0   9409.650391   0.514708   0.011300   \n",
      "1  ID_2  20010.083333    20100.0   8303.049072   0.417707   0.014959   \n",
      "2  ID_3  27260.125000    27437.0  12189.649414   0.447160   0.011428   \n",
      "3  ID_4  41938.125000    42138.0  17866.433594   0.426019   0.009908   \n",
      "4  ID_5  41274.125000    41439.0  14315.041992   0.346828   0.013596   \n",
      "\n",
      "   Feature_6  Feature_7  Feature_8  Feature_9  ...  Feature_3230  \\\n",
      "0   0.045369   2.803803   0.356658   1.803803  ...    382.968383   \n",
      "1   0.080294   2.338398   0.429532   1.338398  ...    452.986164   \n",
      "2   0.046402   2.782842   0.359345   1.782842  ...    419.781765   \n",
      "3   0.034878   3.060655   0.326727   2.060655  ...    439.023968   \n",
      "4   0.065680   2.478506   0.403469   1.478506  ...    485.209184   \n",
      "\n",
      "   Feature_3231  Feature_3232  Feature_3233  Feature_3234  Feature_3235  \\\n",
      "0        2214.0           1.0    136.625113      0.061710           0.0   \n",
      "1        2548.5           1.0    232.564022      0.090548           0.0   \n",
      "2        3400.0           1.0    233.593529      0.068704           0.0   \n",
      "3        5424.0           1.0    427.429572      0.078803           0.0   \n",
      "4        5096.0           1.0    726.731554      0.142608           0.0   \n",
      "\n",
      "   Feature_3236  Feature_3237  Feature_3238  CLASS  \n",
      "0     28.154838      4.174959      0.061710      0  \n",
      "1     27.934229      3.931950      0.090548      1  \n",
      "2     27.904807      4.085035      0.068704      1  \n",
      "3     27.870588      4.011726      0.078803      0  \n",
      "4     28.846909      3.571352      0.142608      0  \n",
      "\n",
      "[5 rows x 3240 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7539332f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 315 entries, 0 to 314\n",
      "Columns: 3240 entries, ID to CLASS\n",
      "dtypes: float64(3238), int64(1), object(1)\n",
      "memory usage: 7.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e3fc542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Feature_1      Feature_2     Feature_3   Feature_4   Feature_5  \\\n",
      "count     315.000000     315.000000    315.000000  315.000000  315.000000   \n",
      "mean    36401.611839   36558.978836  13421.797935    0.399783    0.013326   \n",
      "std     23979.228698   24006.711019   5229.346354    0.064272    0.002885   \n",
      "min      4601.166667    4646.000000   2420.351481    0.137726    0.008904   \n",
      "25%     23287.562500   23443.500000  10245.704590    0.357646    0.011459   \n",
      "50%     34818.166667   35028.000000  13894.792969    0.394076    0.012477   \n",
      "75%     45575.708333   45750.000000  16633.839844    0.434799    0.014242   \n",
      "max    332120.750000  332379.000000  45741.601562    0.643473    0.025418   \n",
      "\n",
      "        Feature_6   Feature_7   Feature_8   Feature_9    Feature_10  ...  \\\n",
      "count  315.000000  315.000000  315.000000  315.000000    315.000000  ...   \n",
      "mean     0.066770    2.572654    0.395949    1.572654    355.140036  ...   \n",
      "std      0.034442    0.305500    0.054492    0.305500   5460.014132  ...   \n",
      "min      0.028169    1.684709    0.304269    0.684709      1.262551  ...   \n",
      "25%      0.046652    2.403035    0.359990    1.403035     14.214779  ...   \n",
      "50%      0.055314    2.624547    0.381018    1.624547     24.110200  ...   \n",
      "75%      0.072065    2.777867    0.416141    1.777867     43.724701  ...   \n",
      "max      0.266032    3.286567    0.603905    2.286567  96940.788837  ...   \n",
      "\n",
      "       Feature_3230  Feature_3231  Feature_3232  Feature_3233  Feature_3234  \\\n",
      "count    315.000000    315.000000         315.0    315.000000    315.000000   \n",
      "mean     458.273347   4580.805291           1.0    620.374167      0.112015   \n",
      "std       39.628050   2980.121623           0.0   1254.417871      0.043563   \n",
      "min      309.374029    591.333333           1.0     45.791124      0.058477   \n",
      "25%      432.298489   2881.000000           1.0    245.299821      0.083622   \n",
      "50%      460.598280   4377.000000           1.0    424.561776      0.103960   \n",
      "75%      484.566083   5769.000000           1.0    702.791528      0.131579   \n",
      "max      636.069588  40797.000000           1.0  20921.640194      0.512823   \n",
      "\n",
      "       Feature_3235  Feature_3236  Feature_3237  Feature_3238       CLASS  \n",
      "count         315.0    315.000000    315.000000    315.000000  315.000000  \n",
      "mean            0.0     28.510670      3.792381      0.112015    0.393651  \n",
      "std             0.0      1.711272      0.257607      0.043563    0.489336  \n",
      "min             0.0     16.430985      1.995746      0.058477    0.000000  \n",
      "25%             0.0     27.691774      3.655440      0.083622    0.000000  \n",
      "50%             0.0     28.424340      3.815115      0.103960    0.000000  \n",
      "75%             0.0     29.450389      3.963320      0.131579    1.000000  \n",
      "max             0.0     35.149153      4.271132      0.512823    1.000000  \n",
      "\n",
      "[8 rows x 3239 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cb16fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID  Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
      "0    False      False      False      False      False      False      False   \n",
      "1    False      False      False      False      False      False      False   \n",
      "2    False      False      False      False      False      False      False   \n",
      "3    False      False      False      False      False      False      False   \n",
      "4    False      False      False      False      False      False      False   \n",
      "..     ...        ...        ...        ...        ...        ...        ...   \n",
      "310  False      False      False      False      False      False      False   \n",
      "311  False      False      False      False      False      False      False   \n",
      "312  False      False      False      False      False      False      False   \n",
      "313  False      False      False      False      False      False      False   \n",
      "314  False      False      False      False      False      False      False   \n",
      "\n",
      "     Feature_7  Feature_8  Feature_9  ...  Feature_3230  Feature_3231  \\\n",
      "0        False      False      False  ...         False         False   \n",
      "1        False      False      False  ...         False         False   \n",
      "2        False      False      False  ...         False         False   \n",
      "3        False      False      False  ...         False         False   \n",
      "4        False      False      False  ...         False         False   \n",
      "..         ...        ...        ...  ...           ...           ...   \n",
      "310      False      False      False  ...         False         False   \n",
      "311      False      False      False  ...         False         False   \n",
      "312      False      False      False  ...         False         False   \n",
      "313      False      False      False  ...         False         False   \n",
      "314      False      False      False  ...         False         False   \n",
      "\n",
      "     Feature_3232  Feature_3233  Feature_3234  Feature_3235  Feature_3236  \\\n",
      "0           False         False         False         False         False   \n",
      "1           False         False         False         False         False   \n",
      "2           False         False         False         False         False   \n",
      "3           False         False         False         False         False   \n",
      "4           False         False         False         False         False   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "310         False         False         False         False         False   \n",
      "311         False         False         False         False         False   \n",
      "312         False         False         False         False         False   \n",
      "313         False         False         False         False         False   \n",
      "314         False         False         False         False         False   \n",
      "\n",
      "     Feature_3237  Feature_3238  CLASS  \n",
      "0           False         False  False  \n",
      "1           False         False  False  \n",
      "2           False         False  False  \n",
      "3           False         False  False  \n",
      "4           False         False  False  \n",
      "..            ...           ...    ...  \n",
      "310         False         False  False  \n",
      "311         False         False  False  \n",
      "312         False         False  False  \n",
      "313         False         False  False  \n",
      "314         False         False  False  \n",
      "\n",
      "[315 rows x 3240 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df.isnull()) #Check for missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63e8f941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_5',\n",
      "       'Feature_6', 'Feature_7', 'Feature_8', 'Feature_9',\n",
      "       ...\n",
      "       'Feature_3230', 'Feature_3231', 'Feature_3232', 'Feature_3233',\n",
      "       'Feature_3234', 'Feature_3235', 'Feature_3236', 'Feature_3237',\n",
      "       'Feature_3238', 'CLASS'],\n",
      "      dtype='object', length=3240)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87a58639",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_df.drop(columns=['ID', 'CLASS'])\n",
    "y = train_df['CLASS']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e298b1",
   "metadata": {},
   "source": [
    "Data Split and Scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0eac3547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs: 2231\n",
      "Infs: 4\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"NaNs:\", X_train.isnull().sum().sum())\n",
    "\n",
    "print(\"Infs:\", np.isinf(X_train).sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1d23030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Inf and -Inf with NaN\n",
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_val.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Fill all NaNs with the column mean\n",
    "X_train.fillna(X_train.mean(), inplace=True)\n",
    "X_val.fillna(X_val.mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5caf293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683b4ba8",
   "metadata": {},
   "source": [
    "Train Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6824ef3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6031746031746031\n",
      "AUROC: 0.5884210526315788\n",
      "Sensitivity (Recall): 0.44\n",
      "Specificity: 0.7105263157894737\n",
      "F1 Score: 0.46808510638297873\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_val_scaled)\n",
    "y_prob = logreg.predict_proba(X_val_scaled)[:, 1]  # Probability of class 1\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"AUROC:\", roc_auc_score(y_val, y_prob))\n",
    "print(\"Sensitivity (Recall):\", recall_score(y_val, y_pred))\n",
    "print(\"Specificity:\", tn / (tn + fp))\n",
    "print(\"F1 Score:\", f1_score(y_val, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
